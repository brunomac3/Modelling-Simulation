{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b5942c2-ffe7-4f30-85e4-df43472c80bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Baseline Evaluation ---\n",
      "Running 10 episodes with a RANDOM AGENT.\n",
      "The simulation window will open. It will be fast because the agent crashes quickly!\n",
      "  ... Episode 10 / 10 complete.\n",
      "\n",
      "--- Evaluation Complete. ---\n",
      "Raw results for all 10 episodes saved to: random_baseline_agent/instant_runs/run_20251114_123336.csv\n",
      "\n",
      "--- Final Metrics Summary (Random Agent Baseline) ---\n",
      "Summary metrics file saved to: random_baseline_agent/summary/summary_20251114_123336.csv\n",
      "Collision Rate               |   0.9000\n",
      "Average Speed (m/s)          |   0.3110\n",
      "Avg Lane Changes / Episode   |   6.4000\n",
      "Average Reward / Episode     |  12.9860\n",
      "Speed Limit Compliance       |   1.0000\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import highway_env\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Configuration ---\n",
    "N_EPISODES = 50  # How many full episodes to run\n",
    "SPEED_LIMIT_MS = 30.0 # The default speed limit in highway-v0 is 30 m/s\n",
    "BASE_OUTPUT_DIR = \"random_baseline_agent\" # Base directory for all results\n",
    "\n",
    "# --- Setup ---\n",
    "# YOUR CHANGE: Define sub-directories for raw runs and summaries\n",
    "RAW_RUNS_DIR = os.path.join(BASE_OUTPUT_DIR, \"instant_runs\")\n",
    "SUMMARY_DIR = os.path.join(BASE_OUTPUT_DIR, \"summary\")\n",
    "\n",
    "# Create all directories if they don't exist\n",
    "os.makedirs(RAW_RUNS_DIR, exist_ok=True)\n",
    "os.makedirs(SUMMARY_DIR, exist_ok=True)\n",
    "\n",
    "# --- Data Storage ---\n",
    "# We'll store the results of each episode in this list\n",
    "all_episode_stats = []\n",
    "\n",
    "print(f\"--- Starting Baseline Evaluation ---\")\n",
    "print(f\"Running {N_EPISODES} episodes with a RANDOM AGENT.\")\n",
    "print(\"The simulation window will open. It will be fast because the agent crashes quickly!\")\n",
    "\n",
    "# 1. Create the environment\n",
    "# YOUR CHANGE: Added render_mode='human' to see the simulation\n",
    "env = gym.make('highway-v0', render_mode='human')\n",
    "\n",
    "# Start the main loop to run N_EPISODES\n",
    "for i in range(N_EPISODES):\n",
    "    \n",
    "    # --- Per-Episode Counters ---\n",
    "    current_episode_reward = 0\n",
    "    current_episode_steps = 0\n",
    "    current_episode_speed_sum = 0\n",
    "    current_episode_lane_changes = 0\n",
    "    current_episode_speed_limit_violations = 0\n",
    "    \n",
    "    # 2. Reset the environment for a new episode\n",
    "    obs, info = env.reset()\n",
    "    done = truncated = False\n",
    "    \n",
    "    # 3. Inner loop: run one full episode\n",
    "    while not (done or truncated):\n",
    "        \n",
    "        # --- The \"Brain\": A Random Agent ---\n",
    "        action = env.action_space.sample() \n",
    "        \n",
    "        # 4. Take the action\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        \n",
    "        # --- Collect Metrics ---\n",
    "        current_episode_reward += reward\n",
    "        current_episode_steps += 1\n",
    "        \n",
    "        # Get Ego Vehicle speed (it's the first vehicle in the observation)\n",
    "        # obs[0] is the ego car, obs[0][3] is its 'vx' (longitudinal velocity)\n",
    "        ego_speed = obs[0][3] \n",
    "        current_episode_speed_sum += ego_speed\n",
    "        \n",
    "        # Check for lane change\n",
    "        if action == 0 or action == 2: # 0=LANE_LEFT, 2=LANE_RIGHT\n",
    "            current_episode_lane_changes += 1\n",
    "            \n",
    "        # Check for speed limit compliance\n",
    "        if ego_speed > SPEED_LIMIT_MS:\n",
    "            current_episode_speed_limit_violations += 1\n",
    "            \n",
    "        # Optional: Add a tiny sleep to make it more watchable\n",
    "        # time.sleep(0.01) # You can uncomment this if it runs too fast\n",
    "\n",
    "    # --- Episode Finished: Save Stats ---\n",
    "    # `info['crashed']` is True if the episode ended in a collision\n",
    "    was_collision = info.get('crashed', False)\n",
    "    \n",
    "    # Calculate averages for this episode (add 1e-6 to avoid divide by zero if steps=0)\n",
    "    avg_speed = current_episode_speed_sum / (current_episode_steps + 1e-6)\n",
    "    speed_compliance_frac = 1.0 - (current_episode_speed_limit_violations / (current_episode_steps + 1e-6))\n",
    "    \n",
    "    # Store all metrics in a dictionary\n",
    "    stats = {\n",
    "        \"episode\": i + 1,\n",
    "        \"collision\": was_collision,\n",
    "        \"total_reward\": current_episode_reward,\n",
    "        \"avg_speed_ms\": avg_speed,\n",
    "        \"lane_changes\": current_episode_lane_changes,\n",
    "        \"speed_compliance\": speed_compliance_frac\n",
    "    }\n",
    "    all_episode_stats.append(stats)\n",
    "    \n",
    "    # Print progress\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\"  ... Episode {i+1} / {N_EPISODES} complete.\")\n",
    "\n",
    "# --- All Episodes Done: Final Report ---\n",
    "env.close()\n",
    "print(\"\\n--- Evaluation Complete. ---\")\n",
    "\n",
    "# Convert the list of dictionaries into a pandas DataFrame\n",
    "df = pd.DataFrame(all_episode_stats)\n",
    "\n",
    "# YOUR CHANGE: Save the raw DataFrame to the 'instant_runs' directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"run_{timestamp}.csv\"\n",
    "output_path = os.path.join(RAW_RUNS_DIR, filename)\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Raw results for all {N_EPISODES} episodes saved to: {output_path}\")\n",
    "\n",
    "\n",
    "# --- Calculate and Print Final Metrics Table ---\n",
    "print(\"\\n--- Final Metrics Summary (Random Agent Baseline) ---\")\n",
    "\n",
    "# We use .mean() to get the average of all episodes\n",
    "final_metrics = {\n",
    "    \"Collision Rate\": df['collision'].mean(),\n",
    "    \"Average Speed (m/s)\": df['avg_speed_ms'].mean(),\n",
    "    \"Avg Lane Changes / Episode\": df['lane_changes'].mean(),\n",
    "    \"Average Reward / Episode\": df['total_reward'].mean(),\n",
    "    \"Speed Limit Compliance\": df['speed_compliance'].mean()\n",
    "}\n",
    "\n",
    "# YOUR CHANGE: Save the summary metrics to a matching CSV file\n",
    "# Convert the dictionary to a DataFrame for easy saving\n",
    "df_summary = pd.DataFrame(list(final_metrics.items()), columns=['Metric', 'Value'])\n",
    "\n",
    "# Create a new filename for the summary, matching the raw run's timestamp\n",
    "summary_filename = f\"summary_{timestamp}.csv\"\n",
    "summary_output_path = os.path.join(SUMMARY_DIR, summary_filename)\n",
    "df_summary.to_csv(summary_output_path, index=False)\n",
    "\n",
    "print(f\"Summary metrics file saved to: {summary_output_path}\")\n",
    "\n",
    "# Print as a clean table\n",
    "for metric, value in final_metrics.items():\n",
    "    print(f\"{metric:<28} | {value:>8.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568a3e9-b01d-4ac3-bbd8-ef58effcb745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
